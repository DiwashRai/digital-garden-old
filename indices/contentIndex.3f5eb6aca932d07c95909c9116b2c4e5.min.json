{"/":{"title":"Digital Garden Home ðŸŒ±","content":"Welcome to my [digital garden](Digital%20Gardens.md) - I'm Diwash. I have been exploring personal knowledge management for a long time and this site is my experiment with doing so in a more public manner that aligns with the idea of [work with the garage door up](Work%20with%20the%20garage%20door%20up.md).  \n\nYou will mainly find notes about software engineering and productivity, however I am just getting started and plan on talking more about AI, PKM systems, mental models and many more.  \n\nThe notes are laid out in a [network](Networked%20Thinking.md) which may be confusing at first, but should allow for easy exploration. For now feel free to use the graph below to dive right in or the map of contents to choose a topic.\n\n[Map of contents](Map%20of%20contents.md)\n","lastmodified":"2023-03-01T02:53:36.126250768Z","tags":null},"/Activation-Energy":{"title":"Activation Energy","content":"Reference:  https://www.makeuseof.com/tag/7-mental-models-get-work-done/ | [Atomic Habits](Sources/Atomic%20Habits.md)  \nTopics: [Productivity](Topics/Productivity.md)  \n\n---\nThe more complex a task, the higher the activation energy required to start and sustain it.\n- To counter this, target the energy required to **start** a task.\n- Break down tasks into simpler and smaller steps.","lastmodified":"2023-03-01T02:53:36.122250715Z","tags":null},"/Anti-marketing":{"title":"Anti-marketing","content":"Reference:  [Anti Marketing - Andy Matuschak](https://notes.andymatuschak.org/About_these_notes?stackedNotes=z21cgR9K3UcQ5a7yPsj2RUim3oM2TzdBByZu\u0026stackedNotes=z4bK6LaSBRetDzuYkeCs3A8mJ8DufTbK4o6FS)  \nTopics: [Mental Models](Topics/Mental%20Models.md)  \n\n---\n\nA model for presenting your work that forces you to engage people more by talking about all the challenges that happened and how you struggled and overcame those challenges. This goes against most content out there where a presenter may want to make themselves or their project look as good as possible but leads to less personal and less genuine presentation.","lastmodified":"2023-03-01T02:53:36.122250715Z","tags":null},"/Authors/Dr-K":{"title":"Dr. K","content":"","lastmodified":"2023-03-01T02:53:36.122250715Z","tags":null},"/Authors/Fedor-Pikus":{"title":"Fedor Pikus","content":"","lastmodified":"2023-03-01T02:53:36.122250715Z","tags":null},"/Authors/James-Clear":{"title":"James Clear","content":"","lastmodified":"2023-03-01T02:53:36.122250715Z","tags":null},"/Authors/Leon-Hendrix":{"title":"Leon Hendrix","content":"","lastmodified":"2023-03-01T02:53:36.122250715Z","tags":null},"/Authors/Rhiannon-Beaubien":{"title":"Rhiannon Beaubien","content":"","lastmodified":"2023-03-01T02:53:36.122250715Z","tags":null},"/Authors/Scott-Meyers":{"title":"Scott Meyers","content":"","lastmodified":"2023-03-01T02:53:36.122250715Z","tags":null},"/Brain-Dump":{"title":"Brain Dump","content":"\nTopics: [Productivity](Topics/Productivity.md)  \nReference:[Leon Hendrix - Journaled for 1000 days. What I learned.](Sources/Leon%20Hendrix%20-%20Journaled%20for%201000%20days.%20What%20I%20learned..md) | [Getting Things Done](Getting%20Things%20Done.md)  \n\n---\n\nA technique used to offload all of the things that are currently straining you mentally by writing everything you can think of onto a note.\n\nValuable for reducing anxiety and staying productive as the first step of creating a structured plan.","lastmodified":"2023-03-01T02:53:36.122250715Z","tags":null},"/Design-Documents":{"title":"Design Documents","content":"Reference:  [Design Docs at Google](https://www.industrialempathy.com/posts/design-docs-at-google/) |  [What is a design doc in software engineering?](https://www.youtube.com/watch?v=bgHL41e7vgI)  \nTopics: [Software Engineering](Topics/Software%20Engineering.md)   \n\n---\n## What is a design doc?\nDesign documents are relatively subjective and informal documents that the primary author of a software system or feature may write before beginning implementation of the software system or feature.  \n\nThe main purposes of a design document are the following:\n- Identify design issues early on in the process where changes are still cheap.\n\t- ==Potentially contentious aspects of the design should be listed==\n\t- ==Considerations for alternative designs must be shown==\n- Ensure cross-cutting conerns are considered and addressed. e.g. security, privacy, logging etc.\n- Utilise knowledge of senior engineers as a way to incorporate the organisations combined experience into a design.\n- Achieve consensus around a design. Allows for accurate implementation of a design in a collaborative environment as well as a way to settle possible disputes.\n- Function as technical documentation about software systems and especially about design decisions made that may have been forgotten.\n\n## Structure\n- **Context and scope**\n\t- Summary of the landscape where the system will be built and what system actually is.\n- **Goals and non-goals**\n\t- What is the system trying to achieve and more importantly...\n\t- What is the system not trying to achieve. ==Things that could be reasonable goals but are explicitly chosen to not be goals.==\n- **The actual design**\n\t- System-context-diagram\n\t- APIs\n\t- Data storage\n\t- Code and pseudo-code: Should be used sparingly.\n\t- Degree of constraint: Constraint on the solution space. Greenfield projects allow no restrictions, whereas legacy systems enforce a multitude of constraints.\n- **Alternatives considered**\n\t- List alternative designs that could have reasonably achieved similar outcomes\n\t- Focus on the trade-offs that each design makes.\n\t- It is fine to be succint, but balance that with the fact that ==this is the most important section in showing why the chosen design is the best.==\n- **Cross-cutting concerns**\n\t- Ensure cross-cutting concerns have been considered.\n\n## Length\n- Shorter features or incremental improvements may be 'one-pagers'.\n- Larger projects seem to be 10-20 pages.\n\n## Lifecycle\n- Creation and iteration\n- Review\n- Implementation and iteration\n- Maintenance and learning\n\n\n","lastmodified":"2023-03-01T02:53:36.122250715Z","tags":null},"/Digital-Gardens":{"title":"Digital Gardens","content":"References:  [Maggie Appleton - Brief History \u0026 Ethos of Digital Gardens](https://maggieappleton.com/garden-history)  \n[Tom Critchlow - Building digital garden](https://tomcritchlow.com/2019/02/17/building-digital-garden/)  \nTopics:  [Productivity](Topics/Productivity.md)  \n\n---\n\n### Intro\nDigital gardens are an alternative model for thinking about personal sites and blogs that goes against how we have come to think about them. They also support the philosophy of [Work with the garage door up](Work%20with%20the%20garage%20door%20up.md) as you are publishing your notes and thoughts online for all to see.  \n\n### Continuous growth\nDigital gardens treat content not as something that is finalised and published, but something that is in an ever growing state. You are free to make additions to each page when you learn something new or make a new connection.  \n\n### Network of concepts and ideas\nThe content in digital gardens are not laid out in some sort of time based 'stream' but as an [interconnected cluster of nodes](Networked%20Thinking.md). This allows for relationships between different topics/notes to be noticed and linked which can allow for better insights to be gained.  \n\n### Exploration over performance\nDigital gardens have a less performative philosophy. Each page is treated less like polished articles intended to be consumed by an audience, but more like a free form wiki of thought's an ideas that the person may note as they encounter them. You could argue that the primary audience for a digital garden is in fact the 'gardener' themselves. This idea frees the 'gardener' to not have to worry about making every sentence, every page perfect, but to focus on what they're interested in and what would benefit themselves (and perhaps other readers).  \n\n### Playful and experimental\nDigital gardens have a more playful and experimental nature to them. You will find a wide plethora of layouts, templates and languages used to create them. The aim is to find what works for you and to also have some fun so that you continue to maintain the garden. At the end of the day, the battle is to absorb the information that we are bombarded with daily in a way that can be applied in our own lives. For that to happen, we need to find what works for us and we have to stick with it.  \n\n### Summary\n- Digital gardens are continuously evolving and growing. No singular page or note should be considered truly complete as new connections and insights can always be made.\n- Digital gardens are a network of nodes. This allows ideas/concepts to be linked easier and for the value of knowledge growth to be non-linear.\n- Digital gardens value the creators own personal exploration and growth over presenting something as a finished product to an audience which brings with it a more performative mindset.\n- Digital gardens are playful and experimental as they provide more value to us, the more fun we are having and the more personalised the garden is to our own needs.","lastmodified":"2023-03-01T02:53:36.122250715Z","tags":null},"/Getting-Things-Done":{"title":"Getting Things Done","content":"\n","lastmodified":"2023-03-01T02:53:36.122250715Z","tags":null},"/Map-of-contents":{"title":"Map of contents","content":"## Topics\n- [Software Engineering](Topics/Software%20Engineering.md)\n- [Productivity](Topics/Productivity.md)\n- [Mental Models](Topics/Mental%20Models.md)\n- [Journaling](Topics/Journaling.md)\n","lastmodified":"2023-03-01T02:53:36.122250715Z","tags":null},"/Molecules/Task-implementation-framework":{"title":"Task implementation framework","content":"Topics: [Productivity](Topics/Productivity.md)  \nReference: [Brain Dump](Brain%20Dump.md) | [Activation Energy](Activation%20Energy.md)    \n\n---\nPersonal productivity created from a combination of insights from various sources with some real life testing to find something that works best for me.\n\n### Method\n- Brain dump\n- Use brain dump to create check list\n- Optional: Time block tasks from check list\n- Review how well the framework worked for that specific project/task.\n\n### Rationale\n- Brain dump - Helps to get the ball rolling when I don't know where to start\n- Creating a check list/plan before starting helps keep me focused in implementation phase. Having to pause to think what comes next or make a decision on what to tackle next can be just enough to get me distracted.\n- Time blocking - prevents me from taking too long on individual tasks. This can happen when due to analysis paralysis or perfectionism.\n\n\n","lastmodified":"2023-03-01T02:53:36.122250715Z","tags":null},"/Networked-Thinking":{"title":"Networked thinking","content":"Reference:  [Roam Research White Paper](Sources/Roam%20Research%20White%20Paper.md)  \nTopics:  [Productivity](Topics/Productivity.md)  \n\n---\n\nA new method of managing knowledge that is more suited to the modern information age where we have an unprecedented amount of information available. The idea is to think of each bit of knowledge as a singular node in an interconnected network of nodes instead of a more 'cabinet desk' like hierarchical strucuture for your knowledge.  \n\nBenefits include:\n- Ease of storage - No need to try to categorise a new bit of knowledge perfectly so that it sits in the correct location in your hierarchy.\n- Better recollection - You can remember an idea itself, or any other node that it may be connected to or even a series of links to the idea you want to recall.\n- Effortless cross-referencing - ideas can be cross-referenced easily without duplication.\n- Optimised for serendipity - graphical display of node network can allow unexpected insights and connections to be made.\n- 'Collaborative problem solving' - can help separate signal from the noise as you can consider conflicting opinions on the same topic and develop your own understanding or draw your own conclusions.","lastmodified":"2023-03-01T02:53:36.122250715Z","tags":null},"/Obsidian-System":{"title":"Obsidian System","content":"\n-   **Core types:**\n    - atom: the base note type for an individual piece of knowledge derived from a source\n    - molecule: bservation/insight drawn from a single or multiple atoms\n    - topic: Category placeholder. Helps find related notes in obsidian\n    - author: the creator of a piece of content\n    - todo: something I need to fill in\n-   **Source types and associated template:**\n    - book -\u003e book\n    - article: e.g blog post, web article -\u003e infomedia\n    - post: social media / forum -\u003e infomedia\n    - academic: textbook, journal article -\u003e academic\n    - video -\u003e infomedia\n    - podcast -\u003e infomedia\n-   **Atom types:**\n    - tool: something that I can use to solve a problem\n    - framework: a way of thinking about the world\n    - school-of-thought: a historical school of thought\n    - person: someone of note\n    - event: a historical event\n    - heuristic: a \"common wisdom\" way of doing something\n- **Workflow:**\n    -  Find interesting/useful info.\n    - Create a source if the media has multiple useful ideas/concepts. Create an atom if only 1.\n    - Atomise each useful concept.\n    - Come back to atoms every now and then.\n    - Create a molecule if a new insight is made.\n","lastmodified":"2023-03-01T02:53:36.126250768Z","tags":null},"/Parkinsons-law":{"title":"Parkinson's law","content":"Topics: [Productivity](Topics/Productivity.md)  \nReference: https://en.wikipedia.org/wiki/Parkinson%27s_law  \n\n---\n\n\"Work expands so as to fill the time available for it's completion\"\n\nThink of it as a law of physics to work around instead of as 'human nature'. This forces you to push this law to its limit for your own benefit:\n- Micro deadlines - aka 'Time blocking'\n- Experiment with shorter deadlines\n","lastmodified":"2023-03-01T02:53:36.126250768Z","tags":null},"/Sources/AI-revolution-applications":{"title":"AI Revolution Applications","content":"Topics: [[Topics/AI]] \n\n---\n\nAutomated email fee appeal  \nhttps://www.bbc.co.uk/news/uk-england-sussex-64749662\n\nImpartial tone judgement for received emails.  \nTherapy sessions  \nhttps://www.reddit.com/r/ChatGPT/comments/11a1ah9/i_am_getting_obsessed_with_chatgpt_and_its/\n\n","lastmodified":"2023-03-01T02:53:36.126250768Z","tags":null},"/Sources/Atomic-Habits":{"title":"Atomic Habits","content":"\nAuthor: [James Clear](Authors/James%20Clear.md)  \nTopics: [Productivity](Topics/Productivity.md)  \n\n---\n\n## Theme. 1\n\n- Key idea 1 \n- Key idea 2\n\n## Theme 2\n\n- Key idea 3\n- Key idea 4\n","lastmodified":"2023-03-01T02:53:36.126250768Z","tags":null},"/Sources/Branchless-Programming-in-C++":{"title":"Branchless Programming in C++","content":"Link:  [Branchless programming in C++ CppCon video](https://www.youtube.com/watch?v=g-WPhYREFjk)  \nAuthor:  [Fedor Pikus](Authors/Fedor%20Pikus.md)  \nTopics: [Software Engineering](Topics/Software%20Engineering.md)  \n\n---\n\n## Potential benefits\n\n**Common code example 1:**\n```cpp\nf(bool b, unsigned long x, unsigned long\u0026 s)\n{\n    if (b) s+= x;\n}\n```\n130M calls/sec -\u003e 400M calls/sec optimised  \nOptimised version:  \n```cpp\nf(bool b, unsigned long x, unsigned long\u0026 s)\n{\n    s+= b * x; // use boolean as int to multiply 'x'\n}\n```\n\n**Common code example 2:**\n```cpp\nif (x[i] || y[i])\n{\n    // Do something\n}\n```\n150M evaluations/sec -\u003e 570M evaluations/sec\n(Optimisation show in \u003ca href=\"#2b-bitwise-optimisation\"\u003e2.b. bitwise optimisation\u003c/a\u003e)  \n\n## Philosophy for performance\n\nIn order of priority:\n- Get desired result with ==least work==\n    - Use an _optimal_ algorithm\n- Do not do any ==unnecessary work==\n    - Efficiently use language\n- Use ==all available resources==, ==at the same time==, ==all the time==.\n    - Efficient hardware use.\n\n### CPU compute resources\n**Inefficient use of CPU:**\n```cpp\nunsigned long v1[N], v2[N];\nunsigned long a = 0;\nfor (size_t i = 0; i \u003c N; ++i)\n{\n    a += v1[i] * v2[i];\n}\n```\n\nWhy is it inefficient use of CPU?  \nBecause it does not actually load the CPU very much at all as we are only doing one multiplication per iteration. In fact, more calculations can be thrown in for free.  \n\nThe following code will run at the same speed on modern CPUs.  \n```cpp\nunsigned long v1[N], v2[N];\nunsigned long a1 = 0, a2 = 0;\nfor (size_t i = 0; i \u003c N; ++i)\n{\n    a1 += v1[i] * v2[i];\n    a2 += v1[i] + v2[i];\n    ...\n    // in fact you can insert even more operations for 'free'\n}\n```\n\nSounds great! Not quite. You can almost never do that due to ==data dependencies==. In order to do the next computation, you need the result from the first. Things get even worse if there are ==code dependencies.== There may be branches and conditions which means that the CPU now must wait until it knows which ==instructions== to execute as well.  \n\nHaving so much compute power would be useless however if we didn't have some workarounds!\n\n## Pipelining\n```cpp\na += (v1[i] + v2[i]) * (v1[i] - v2[i]);\n```\n\nIn this example you can do the addition and subtraction in the first cycle, then do the multiplication in the second cycle, whilst also doing the addition and subtraction for the next iteration. This creates two _streams_ of instructions that are interleaved that have no data dependency between them at a given cpu cycle.  \n\nThis results in multiple instruction streams that have\n- Dependencies within each stream\n- No data dependencies between streams\n\nThis is great and increases cpu utilisation. However, the next barrier is... **conditional code.**\n\n## Branches\nPipelining requires a continuous stream of instructions. Conditions/Branches mean that the CPU is unsure of the next instruction to place into the pipeline. So what can we do?\n\n**Branch prediction**. The CPU guesses which branch to take and continues pipelining. The ==performance is now based on accuracy of predictions==. However, the branch can be mispredicted and recovering from a ==branch misprediction== is very costly.  \n\nBut how costly is this branch misprediction?\n\n## Experiments\n\n### 1.a. always true -\u003e same branch taken\n\n```cpp\n\n#include \"benchmark/benchmark.h\"\n\n#include \u003cstdlib.h\u003e\n#include \u003cstring.h\u003e\n\nstatic void always_true(benchmark::State\u0026 state) {\n    srand(1);\n    const unsigned int N = state.range(0);\n    std::vector\u003cunsigned long\u003e v1(N), v2(N);\n    std::vector\u003cint\u003e c1(N);\n    for (size_t i = 0; i \u003c N; ++i) {\n       v1[i] = rand();\n       v2[i] = rand();\n       c1[i] = rand() \u003e= 0; // always true\n    }\n    unsigned long* p1 = v1.data();\n    unsigned long* p2 = v2.data();\n    int* b1 = c1.data();\n    for (auto _ : state) {\n        unsigned long a1 = 0, a2 = 0;\n        for (size_t i = 0; i \u003c N; ++i) {\n            if (b1[i]) {\n                a1 += p1[i];\n            } else {\n                a2 *= p2[i];\n            }\n        }\n        benchmark::DoNotOptimize(a1);\n        benchmark::DoNotOptimize(a2);\n        benchmark::ClobberMemory();\n    }\n    state.SetItemsProcessed(N*state.iterations());\n}\n\nBENCHMARK(always_true)-\u003eArg(1\u003c\u003c22);\n\nBENCHMARK_MAIN();\n\n```\n\n**Benchmark result:**\n```shell\nRun on (12 X 4467.28 MHz CPU s)\nCPU Caches:\n  L1 Data 32 KiB (x6)\n  L1 Instruction 32 KiB (x6)\n  L2 Unified 512 KiB (x6)\n  L3 Unified 32768 KiB (x1)\nLoad Average: 0.26, 0.35, 0.45\n\n------------------------------------------------------------------------------\nBenchmark                    Time             CPU   Iterations UserCounters...\n------------------------------------------------------------------------------\nalways_true/4194304    1741613 ns      1734898 ns          430 items_per_second=2.41761G/s\n\n```\n\n### 1.b. random -\u003e 50/50 if branch vs else branch\n\n```cpp\n\n#include \"benchmark/benchmark.h\"\n\n#include \u003cstdlib.h\u003e\n#include \u003cstring.h\u003e\n\nstatic void random(benchmark::State\u0026 state) {\n    srand(1);\n    const unsigned int N = state.range(0);\n    std::vector\u003cunsigned long\u003e v1(N), v2(N);\n    std::vector\u003cint\u003e c1(N);\n    for (size_t i = 0; i \u003c N; ++i) {\n       v1[i] = rand();\n       v2[i] = rand();\n       c1[i] = rand() \u0026 0x1; // randomly true/false\n    }\n    unsigned long* p1 = v1.data();\n    unsigned long* p2 = v2.data();\n    int* b1 = c1.data();\n    for (auto _ : state) {\n        unsigned long a1 = 0, a2 = 0;\n        for (size_t i = 0; i \u003c N; ++i) {\n            if (b1[i]) {\n                a1 += p1[i];\n            } else {\n                a2 *= p2[i];\n            }\n        }\n        benchmark::DoNotOptimize(a1);\n        benchmark::DoNotOptimize(a2);\n        benchmark::ClobberMemory();\n    }\n    state.SetItemsProcessed(N*state.iterations());\n}\n\nBENCHMARK(random)-\u003eArg(1\u003c\u003c22);\n\nBENCHMARK_MAIN();\n\n```\n\n**Benchmark result:**\n```shell\nRun on (12 X 4467.28 MHz CPU s)\nCPU Caches:\n  L1 Data 32 KiB (x6)\n  L1 Instruction 32 KiB (x6)\n  L2 Unified 512 KiB (x6)\n  L3 Unified 32768 KiB (x1)\nLoad Average: 0.26, 0.36, 0.44\n\n-------------------------------------------------------------------------\nBenchmark               Time             CPU   Iterations UserCounters...\n-------------------------------------------------------------------------\nrandom/4194304   12131503 ns     12091002 ns           58 items_per_second=346.895M/s\n```\n\nAs you can see, the mispredicted benchmark is significantly slower. By about 7.7 times. Branch mispredictions are extremely costly.\n\nBut how do we detect when branch misprediction is a problem? By using a cpu profiling tool such as **==perf==**.\n\n### Using perf to detect branch mispredictions.\n\nThe command to run is `perf stat \u003cprogram\u003e`  \nThe result for the 1a the 'always true' program is:  \n```shell\ntask-clock:u                     #    1.000 CPUs utilized\ncontext-switches:u               #    0.000 /sec\ncpu-migrations:u                 #    0.000 /sec\npage-faults:u                    #   58.862 K/sec\ncycles:u                         #    4.217 GHz                      (83.30%)\nstalled-cycles-frontend:u        #    1.63% frontend cycles idle     (83.35%)\nstalled-cycles-backend:u         #    0.17% backend cycles idle      (83.35%)\ninstructions:u                   #    3.68  insn per cycle\n                          #    0.00  stalled cycles per insn  (83.34%)\nbranches:u                       #    4.399 G/sec                    (83.35%)\nbranch-misses:u                  #    0.00% of all branches          (83.31%)\n```\n\n0% (or usually close to that) branch-misses. Compare that to 1b.\n\n```shell\ntask-clock:u                     #    1.000 CPUs utilized\ncontext-switches:u               #    0.000 /sec\ncpu-migrations:u                 #    0.000 /sec\npage-faults:u                    #   52.165 K/sec\ncycles:u                         #    4.258 GHz                      (83.30%)\nstalled-cycles-frontend:u        #    0.87% frontend cycles idle     (83.31%)\nstalled-cycles-backend:u         #    0.00% backend cycles idle      (83.31%)\ninstructions:u                   #    0.88  insn per cycle\n                          #    0.01  stalled cycles per insn  (83.33%)\nbranches:u                       #    1.078 G/sec                    (83.40%)\nbranch-misses:u                  #   12.16% of all branches          (83.35%)\n```\n\n12% branch-misprediction. With the context of the second perf result, you can see that ==instructions per cycle== is also massively down from 3.68 -\u003e 0.88.  \n\n### 1.c. alternating if branch and else branch -\u003e predictable branching\n\n```cpp\n\n#include \"benchmark/benchmark.h\"\n\n#include \u003cstdlib.h\u003e\n#include \u003cstring.h\u003e\n\nstatic void alternating(benchmark::State\u0026 state) {\n    srand(1);\n    const unsigned int N = state.range(0);\n    std::vector\u003cunsigned long\u003e v1(N), v2(N);\n    std::vector\u003cint\u003e c1(N);\n    for (size_t i = 0; i \u003c N; ++i) {\n        v1[i] = rand();\n        v2[i] = rand();\n        if (i == 0) c1[i] = rand() \u003e=0;\n        else c1[i] = !c1[i-1]; // alternate true and false\n    }\n    unsigned long* p1 = v1.data();\n    unsigned long* p2 = v2.data();\n    int* b1 = c1.data();\n    for (auto _ : state) {\n        unsigned long a1 = 0, a2 = 0;\n        for (size_t i = 0; i \u003c N; ++i) {\n            if (b1[i]) {\n                a1 += p1[i];\n            } else {\n                a2 *= p2[i];\n            }\n        }\n        benchmark::DoNotOptimize(a1);\n        benchmark::DoNotOptimize(a2);\n        benchmark::ClobberMemory();\n    }\n    state.SetItemsProcessed(N*state.iterations());\n}\n\nBENCHMARK(alternating)-\u003eArg(1\u003c\u003c22);\n\nBENCHMARK_MAIN();\n\n```\n**Benchmark result:**\n```shell\nRun on (12 X 4467.28 MHz CPU s)\nCPU Caches:\n  L1 Data 32 KiB (x6)\n  L1 Instruction 32 KiB (x6)\n  L2 Unified 512 KiB (x6)\n  L3 Unified 32768 KiB (x1)\nLoad Average: 0.89, 0.46, 0.42\n------------------------------------------------------------------------------\nBenchmark                    Time             CPU   Iterations UserCounters...\n------------------------------------------------------------------------------\nalternating/4194304    2529638 ns      2523583 ns          280 items_per_second=1.66204G/s\n```\n\n**Perf result:**\n```shell\ntask-clock:u                     #    0.999 CPUs utilized\ncontext-switches:u               #    0.000 /sec\ncpu-migrations:u                 #    0.000 /sec\npage-faults:u                    #   57.934 K/sec\ncycles:u                         #    4.229 GHz                      (83.30%)\nstalled-cycles-frontend:u        #    0.74% frontend cycles idle     (83.32%)\nstalled-cycles-backend:u         #    0.22% backend cycles idle      (83.31%)\ninstructions:u                   #    2.39  insn per cycle\n                          #    0.00  stalled cycles per insn  (83.34%)\nbranches:u                       #    3.029 G/sec                    (83.39%)\nbranch-misses:u                  #    0.00% of all branches          (83.34%)\n```\n\nWith an alternating pattern, you can see that it is slower than the 'alway true' program, but faster than the horribly mispredicted one. 440 vs 58 vs 280.  \n\nThe branch-misses are also at 0%. The CPU figured out the pattern!  \n\n### 2.a. Predictable result, unpredictable branch\n\nThis is a case where you have an || condition.\n```cpp\n\n#include \"benchmark/benchmark.h\"\n\n#include \u003cstdlib.h\u003e\n#include \u003cstring.h\u003e\n\nstatic void random_predictable(benchmark::State\u0026 state) {\n    srand(1);\n    const unsigned int N = state.range(0);\n    std::vector\u003cunsigned long\u003e v1(N), v2(N);\n    std::vector\u003cint\u003e c1(N);\n    std::vector\u003cint\u003e c2(N);\n    for (size_t i = 0; i \u003c N; ++i) {\n        v1[i] = rand();\n        v2[i] = rand();\n        c1[i] = rand() \u0026 0x1;\n        c2[i] = !c1[i];\n    }\n    unsigned long* p1 = v1.data();\n    unsigned long* p2 = v2.data();\n    int* b1 = c1.data();\n    int* b2 = c2.data();\n    for (auto _ : state) {\n        unsigned long a1 = 0, a2 = 0;\n        for (size_t i = 0; i \u003c N; ++i) {\n            if (b1[i] || b2[i]) {\n                a1 += p1[i];\n            } else {\n                a2 *= p2[i];\n            }\n        }\n        benchmark::DoNotOptimize(a1);\n        benchmark::DoNotOptimize(a2);\n        benchmark::ClobberMemory();\n    }\n    state.SetItemsProcessed(N*state.iterations());\n}\n\nBENCHMARK(random_predictable)-\u003eArg(1\u003c\u003c22);\n\nBENCHMARK_MAIN();\n\n```\n\nthe 'if' condtion is always true as b1 is true when b2 isn't and viceversa. Although the result is predictable, the branch taken is not. This is because the branch is either through b1 or b2. Here are the benchmark results  \n\n```shell\nRunning ./02-random_predictable\nRun on (12 X 4467.28 MHz CPU s)\nCPU Caches:\n  L1 Data 32 KiB (x6)\n  L1 Instruction 32 KiB (x6)\n  L2 Unified 512 KiB (x6)\n  L3 Unified 32768 KiB (x1)\nLoad Average: 0.42, 0.54, 0.54\n-------------------------------------------------------------------------------------\nBenchmark                           Time             CPU   Iterations UserCounters...\n-------------------------------------------------------------------------------------\nrandom_predictable/4194304   12137243 ns     12055659 ns           58 items_per_second=347.912M/s\n\ntask-clock:u                     #    1.000 CPUs utilized\ncontext-switches:u               #    0.000 /sec\ncpu-migrations:u                 #    0.000 /sec\npage-faults:u                    #   65.941 K/sec\ncycles:u                         #    4.206 GHz                      (83.30%)\nstalled-cycles-frontend:u        #    0.85% frontend cycles idle     (83.30%)\nstalled-cycles-backend:u         #    0.45% backend cycles idle      (83.30%)\ninstructions:u                   #    1.01  insn per cycle\n                          #    0.01  stalled cycles per insn  (83.36%)\nbranches:u                       #    1.195 G/sec                    (83.39%)\nbranch-misses:u                  #   10.82% of all branches          (83.35%)\n```\n\nAs you can see the iterations value is down to 58 and branch-misses is up to 10.82%. Even though the result is the same every time.  \n\nHow can we optimise this?\n\n### 2.b. bitwise optimisation\nHere I will use addition. You can also use logical 'or'.\n```cpp\n\n#include \"benchmark/benchmark.h\"\n\n#include \u003cstdlib.h\u003e\n#include \u003cstring.h\u003e\n\nstatic void bitwise(benchmark::State\u0026 state) {\n    srand(1);\n    const unsigned int N = state.range(0);\n    std::vector\u003cunsigned long\u003e v1(N), v2(N);\n    std::vector\u003cint\u003e c1(N);\n    std::vector\u003cint\u003e c2(N);\n    for (size_t i = 0; i \u003c N; ++i) {\n        v1[i] = rand();\n        v2[i] = rand();\n        c1[i] = rand() \u0026 0x1;\n        c2[i] = !c1[i];\n    }\n    unsigned long* p1 = v1.data();\n    unsigned long* p2 = v2.data();\n    int* b1 = c1.data();\n    int* b2 = c2.data();\n    for (auto _ : state) {\n        unsigned long a1 = 0, a2 = 0;\n        for (size_t i = 0; i \u003c N; ++i) {\n            if (bool(b1[i]) + bool(b2[i])) {\n                a1 += p1[i];\n            } else {\n                a2 *= p2[i];\n            }\n        }\n        benchmark::DoNotOptimize(a1);\n        benchmark::DoNotOptimize(a2);\n        benchmark::ClobberMemory();\n    }\n    state.SetItemsProcessed(N*state.iterations());\n}\n\nBENCHMARK(bitwise)-\u003eArg(1\u003c\u003c22);\n\nBENCHMARK_MAIN();\n```\n\nThe results:  \n```shell\nRunning ./02-bitwise\nRun on (12 X 4467.28 MHz CPU s)\nCPU Caches:\n  L1 Data 32 KiB (x6)\n  L1 Instruction 32 KiB (x6)\n  L2 Unified 512 KiB (x6)\n  L3 Unified 32768 KiB (x1)\nLoad Average: 0.69, 0.50, 0.51\n\n--------------------------------------------------------------------------\nBenchmark                Time             CPU   Iterations UserCounters...\n--------------------------------------------------------------------------\nbitwise/4194304    2113774 ns      2097247 ns          337 items_per_second=1.99991G/s\n\n\ntask-clock:u                     #    1.000 CPUs utilized\ncontext-switches:u               #    0.000 /sec\ncpu-migrations:u                 #    0.000 /sec\npage-faults:u                    #   73.555 K/sec\ncycles:u                         #    4.164 GHz                      (83.33%)\nstalled-cycles-frontend:u        #    1.04% frontend cycles idle     (83.33%)\nstalled-cycles-backend:u         #    0.36% backend cycles idle      (83.33%)\ninstructions:u                   #    4.60  insn per cycle\n                          #    0.00  stalled cycles per insn  (83.33%)\nbranches:u                       #    3.419 G/sec                    (83.33%)\nbranch-misses:u                  #    0.00% of all branches          (83.35%)\n```\n\nHere you can see branch-misses are down to 0% again and iterations are up from 58 to 337.\n\n**Bear in mind,** the optimisation is that instead of evaluating both conditions separately, you calculate both and then check both at the same time. This means you are doing more instructions. ==That is the tradeoff==. This can be important if you, for example, battery life is important to you.  \n\nAdditionally, if the result was not predictable, this would also instead be a performance hit.\n\n### 3.a. Branched unpredictable\nExperiment 3 will consist of taking a loop with 1 branch and showing how we can eliminate the branch completely. The first case is then the branched example.\n\n```cpp\n\n#include \"benchmark/benchmark.h\"\n\n#include \u003cstdlib.h\u003e\n#include \u003cstring.h\u003e\n\nstatic void branched_unpredictable(benchmark::State\u0026 state) {\n    srand(1);\n    const unsigned int N = state.range(0);\n    std::vector\u003cunsigned long\u003e v1(N), v2(N);\n    std::vector\u003cint\u003e c1(N);\n    for (size_t i = 0; i \u003c N; ++i) {\n       v1[i] = rand();\n       v2[i] = rand();\n       c1[i] = rand() \u0026 0x1;\n    }\n    unsigned long* p1 = v1.data();\n    unsigned long* p2 = v2.data();\n    int* b1 = c1.data();\n    for (auto _ : state) {\n        unsigned long a1 = 0, a2 = 0;\n        for (size_t i = 0; i \u003c N; ++i) {\n            if (b1[i]) {\n                a1 += p1[i] - p2[i];\n            } else {\n                a2 *= p2[i] * p2[i];\n            }\n        }\n        benchmark::DoNotOptimize(a1);\n        benchmark::DoNotOptimize(a2);\n        benchmark::ClobberMemory();\n    }\n    state.SetItemsProcessed(N*state.iterations());\n}\n\nBENCHMARK(branched_unpredictable)-\u003eArg(1\u003c\u003c22);\n\nBENCHMARK_MAIN();\n\n```\n\n**Result:**\n```shell\nRunning ./03-branched-unpredictable\nRun on (12 X 4467.28 MHz CPU s)\nCPU Caches:\n  L1 Data 32 KiB (x6)\n  L1 Instruction 32 KiB (x6)\n  L2 Unified 512 KiB (x6)\n  L3 Unified 32768 KiB (x1)\nLoad Average: 0.76, 0.75, 0.63\n\n-----------------------------------------------------------------------------------------\nBenchmark                               Time             CPU   Iterations UserCounters...\n-----------------------------------------------------------------------------------------\nbranched_unpredictable/4194304   13162172 ns     13070350 ns           54 items_per_second=320.902M/s\n\ntask-clock:u                     #    0.999 CPUs utilized\ncontext-switches:u               #    0.000 /sec\ncpu-migrations:u                 #    0.000 /sec\npage-faults:u                    #   51.062 K/sec\ncycles:u                         #    4.230 GHz                      (83.31%)\nstalled-cycles-frontend:u        #    0.87% frontend cycles idle     (83.32%)\nstalled-cycles-backend:u         #    0.20% backend cycles idle      (83.20%)\ninstructions:u                   #    0.88  insn per cycle\n                          #    0.01  stalled cycles per insn  (83.41%)\nbranches:u                       #    1.029 G/sec                    (83.40%)\nbranch-misses:u                  #   11.79% of all branches          (83.36%)\n```\n\n54 iterations, 11.79% branch-misses.\n\n### 3.b. branchless unpredictable\nThis example now shows how we can eliminate the branch completely.\n\n```cpp\n\n#include \"benchmark/benchmark.h\"\n\n#include \u003cstdlib.h\u003e\n#include \u003cstring.h\u003e\n\nstatic void branchless_unpredictable(benchmark::State\u0026 state) {\n    srand(1);\n    const unsigned int N = state.range(0);\n    std::vector\u003cunsigned long\u003e v1(N), v2(N);\n    std::vector\u003cint\u003e c1(N);\n    for (size_t i = 0; i \u003c N; ++i) {\n       v1[i] = rand();\n       v2[i] = rand();\n       c1[i] = rand() \u0026 0x1;\n    }\n    unsigned long* p1 = v1.data();\n    unsigned long* p2 = v2.data();\n    int* b1 = c1.data();\n    for (auto _ : state) {\n        unsigned long a1 = 0, a2 = 0;\n        for (size_t i = 0; i \u003c N; ++i) {\n            unsigned long s1[2] = {0, p1[i] - p2[i]};\n            unsigned long s2[2] = {p1[i] * p2[i], 0};\n            a1 += s1[bool(b1[i])];\n            a2 += s2[bool(b1[i])];\n        }\n        benchmark::DoNotOptimize(a1);\n        benchmark::DoNotOptimize(a2);\n        benchmark::ClobberMemory();\n    }\n    state.SetItemsProcessed(N*state.iterations());\n}\n\nBENCHMARK(branchless_unpredictable)-\u003eArg(1\u003c\u003c22);\n\nBENCHMARK_MAIN();\n\n```\n\nWhat we are doing is essentially calculating both branches and storing them in an array. Then using the bool 'b1' as an integer to add both branch results to 'a1' and 'a2'. The key being that s1 and s2 store a '0' value in position 0 and 1 respectively. So how effective is this?\n\n```shell\nRunning ./03-branchless-unpredictable.cpp\nRun on (12 X 4467.28 MHz CPU s)\nCPU Caches:\n  L1 Data 32 KiB (x6)\n  L1 Instruction 32 KiB (x6)\n  L2 Unified 512 KiB (x6)\n  L3 Unified 32768 KiB (x1)\nLoad Average: 0.30, 0.40, 0.51\n\n-------------------------------------------------------------------------------------------\nBenchmark                                 Time             CPU   Iterations UserCounters...\n-------------------------------------------------------------------------------------------\nbranchless_unpredictable/4194304    4246080 ns      4207040 ns          166 items_per_second=996.973M/s\n\ntask-clock:u                     #    0.998 CPUs utilized\ncontext-switches:u               #    0.000 /sec\ncpu-migrations:u                 #    0.000 /sec\npage-faults:u                    #   48.458 K/sec\ncycles:u                         #    4.253 GHz                      (83.31%)\nstalled-cycles-frontend:u        #    1.16% frontend cycles idle     (83.34%)\nstalled-cycles-backend:u         #    0.17% backend cycles idle      (83.37%)\ninstructions:u                   #    3.69  insn per cycle\n                          #    0.00  stalled cycles per insn  (83.36%)\nbranches:u                       #    1.301 G/sec                    (83.29%)\nbranch-misses:u                  #    0.00% of all branches          (83.32%)\n```\n\nThe iterations have increased from 54 to 166 and branch-misses are now 0% again.  \n\nNote that the iterations has not increased as drastically as we are actually doing a lot more work, but there is still a significant performance boost.\n\nThis optimisation is effective under two circumstances:\n1. Extra computations are small\n2. Branch is poorly predicted\n\n## Closing thoughts\n\n- Predicted branches are cheap\n- Mispredictions are **very** expensive\n- **ALWAYS** use a profiler to detect optimisation locations.\n- Don't fight the compiler as it can often do the optimisations for you.","lastmodified":"2023-03-01T02:53:36.126250768Z","tags":null},"/Sources/Effective-C++":{"title":"Effective C++","content":"\nAuthor: [Scott Meyers](Authors/Scott%20Meyers.md)  \nTopics: [Software Engineering](Topics/Software%20Engineering.md)  \n\n---\n\n## Ch1: Accustoming yourself to C++  \n\n### **Item 1:** View C++ as a federation of languages  \nC++ is better understood as a group of related sub-languages. These are:\n- C\n- Object-oriented C++\n- Template C++\n- The STL\n\nThis is important to keep in mind as different sublanguages have different effective strategies and different conventions.\n\n\n### **Item 2:** Prefer consts, enums, and inlines to \\#defines  \nRule could also be called \"Prefer the compiler over the preprocessor\".   \n\n```cpp\n// BAD\n#define ASPECT_RATIO 1.653\n\n// GOOD\nconst double AspectRation = 1.653;\nconst char* const authorName = \"Scott Meyers\";\nconst std::string authorName(\"Scott Meyers\");\n```\n\nThe preprocessor will blindly subsitute ASPECT_RATIO for 1.653 resulting in multple copies in the object code.   \n\n```cpp\n// BAD\n#define CALL_WITH_MAX(a,b) f((a) \u003e (b) ? (a) : (b))\n\n// GOOD\ntemplate\u003ctypename T\u003e\ninline void callWithMax(const T\u0026 a, const T\u0026 b)\n{\n    f(a \u003e b ? a: b);\n}\n```\nFunction like macros can be very error prone. Calling `CALL_WITH_MAX(++a, b)` for example results in a being incremented twice.\n\n\n### **Item 3:** Use const whenever possible  \n- Helps detect usage errors.\n- Using `const` in function declaration is extremely powerful so make use of it. It can refer to the function's return value, the individual parameters or even the function as a whole.\n- Compilers enforce 'bitwise constness' but you should program using 'logical constness'.\n\t- Bitwise constness/Physical: does not modify any of object's data members\n\t- Logical constness: Some data members of an object can be modified but should be in ways the client cannot detect. Achieved using `mutable`. Also considers situations where something is bitwise const, but does not behave const. e.g. the altering of data members by returning non-const references.\n- When const and non-const member functions have similar implementations, avoid duplication by calling const version in the non-const function and using `const_cast`.\n\n\n### **Item 4:** Make sure objects are initialised before use\nThe rules about when objects initialisation is guaranteed or not is too complicated to be worth memorising. Avoid the issue by ==always initialising==. \n- For non-member built in types, this needs to be done manually. e.g. `int x = 0;`\n- For the rest, initialisation is the responsibility of the constructors and the use of initialisation list is preferred.\n\n\n## Ch2: Constructors, destructors and assignment operators  \n\n### **Item 5:** Know what functions C++ silently writes and calls\nCompilers will declare the following if you do not do so yourself:\n- Copy constructor\n- Copy assignment operator\n- Destructor\n\nIf no constructors are declared at all, compilers will also declare:\n- Default constructor\n\n### **Item 6:** Explicitly disallow the use of compiler-generated functions you do not want\nAn example of an unwanted generated function is a copy constructor and copy assignment operator for objects that should not be copied.  \n\n```cpp\nHomeForSale h1;\nHomeForSale h2;\nHomeForSale h3(h1); //should not compile\nh1 = h2;            // should not compile\n```\n\nTo achieve this there is a ==well known trick==. Declare the functions private and do not implement them.\n\n```cpp\nclass HomeForSale {\npublic:\n    ...\nprivate:\n    HomeForSale(const HomeForSale\u0026);\n    HomeForSale\u0026 operator=(ocnst HomeForSale\u0026);\n}\n```\n\nThis trick works and generates a link-time error. It is possible to move\nit up to a compile time error by declaring the functions private in a base\nclass designed just to prevent copying.\n\n\u003e[!abstract] Summary\n\u003e- Disallow compiler generated function by declaring the function private and not providing an implementation\n\n### **Item 7:** Declare destructors virtual in polymorphic base classes\nLets say you have a base class `TimeKeeper` and some derivided classes\nthat inherit from it:  \n- AtomicClock\n- WaterClock\n- WristWatch\n\nIf you try to delete a derived class (e.g. WristWatch) with a base class\npointer (TimeKeeper), the results are undefined. Most likely, the derived\nclass parts of the object won't be deleted. This is a good way to leak\nmemory.\n\nSolution is simple: ==give the base class a virtual destructor==.\n\nHowever, when a class is not meant to be used as a base class, making it\nvirtual is usually a bad idea. This is because virtual functions require the\nuse of vptr (\"virtual table pointers\") which increases the size of the type.\nA simple data type that contains two ints, would go from 64bits in size to\n128bits. An increase of 100%. It also makes the object less portable to C.\n\nIf you want to make a class abstract that does not have functions to make\nvirtual, you can just give it a pure virtual destructor. This is because a\nabstract classes are meant to be base classes and base classes should\nhave a virtual destructor.\n\n\u003e [!abstract] Summary\n\u003e - Polymorphic base classes should declare virtual destructors.\n\u003e - Any class with virtual functions should have a virtual destructor.\n\u003e - Classes that aren't base classes should not declare virtual destructors.\n\u003e - Use a pure virtual destructor to make classes abstract that do not have functions\n\n### **Item 8:** Prevent exceptions from leaving destructors  \nC++ allows destructors to emit exceptions but it is heavily discouraged.\nThis is because if an exception is thrown, for example, in a vector\ncontaining 10 widgets, the rest of the widgets still need to be deleted or\nthere will be leak. However, if you then have another exception when\ndeleting the other widgets, now you have two simultaneous exceptions\nwhich results in undefined behaviour.\n\nExample class that closes database connection in destructor:\n```cpp\nclass DBConn {\npublic:\n    ...\n    ~DBConn()\n    {\n        db.close();\n    }\nprivate:\n    DBConnection db;\n}\n```\nThis will cause issues if the call to close results in an exception. The\nexception will be propagated.\n\nThere are two options to fix this:  \n- ==Terminate the program== (e.g. with std::abort()). This is a reasonable solution if the program can no longer run due to the error.\n- ==Swallow the exception==. This is a bad idea as we need to know when something fails.\n\nThe actual ideal solution is to create a function that closes the connection\nin the DBConn interface so the client can react to the exception. Then\nthe backup call to 'close()' can still be placed in the destructor. This may\nseem like it goes against *item 11*, by placing an extra burden on the client,\nhowever it is not as it actually **gives** them a chance to react to the\nexception.\n\n\u003e [!abstract] Summary\n\u003e - Destructors should never emit exceptions.\n\u003e - If a classes clients need to react to exceptions during an operation, offer a regular 'non-destrcutor' function that performs the operation.\n\n### **Item 9:** Never call virtual functions during construction or destruction\nDon't call virtual functions during construction or destruction as they won't\ndo what you expect them to. If they did, it would lead to undefined\nbehaviour.\n\nExample: Say you have a base class `Transaction` that is inherited by a \nclass called `BuyTransaction`. If you have a virtual function in Transaction\nthat is called during construction, it will call the base class version. Not\nthe derived version. This is because the base class is constructed first so\nthe derived members will not have been constructed yet.\n\n\u003e [!abstract] Summary\n\u003e - Don't call virtual functions from constructors or destructors.\n\n### **Item 10:** Have assignment operators return a reference to `this`\nAssignments can be chained together and is right associative.\n```cpp\nint x, y, z;\nx = y = z = 15;\n//equivalent to\nx = (y = (z = 15));\n```\nThis is implemented by assignments returning a reference to it's left hand argument. This is the convention that should be followed.\n\n```cpp\nclass Widget {\npublic:\n    ...\n    Widget\u0026 operator=(const Widget\u0026 rhs)\n    {\n        ...\n        return *this;\n    }\n    ...\n}\n```\n\n\u003e [!abstract] Summary\n\u003e - Have assignment operators return a reference to `*this`\n\n### **Item 11:** Handle assignment to self in operator=.\nThis looks silly but is allowed:\n```cpp\nWidget w;\n...\nw = w;\n```\n``\nIf it's allowed, clients will end up doing it. A less obvious version may look\nlike this:\n```cpp\n// potential assignment to selfs\na[i] = a[j];\n*px = *py;\n```\n\nWhen writing resource managing classes you can fall into the trap of\naccidentally releasing a resource before you're done with it:\n```cpp\nclass Bitmap {...};\nclass Widget{\n    ...\nprivate:\n    Bitmap *pb;\n}\n\nWidget\u0026 Widget::operator=(const Widget\u0026 rhs)\n{\n    delete pb;\n    pb = new Bitmap(*rhs.pb);\n    return *this;\n}\n```\n\nHere you delete rhs not realising that it is the same as `this`. The\ntraditional fix is this:\n```cpp\n\nWidget\u0026 Widget::operator=(const Widget\u0026 rhs)\n{\n    if (this == \u0026rhs) return *this;\n    \n    delete pb;\n    pb = new Bitmap(*rhs.pb);\n    return *this;\n}\n```\nThis is now self-assignment safe but not exception safe. If `new Bitmap`\ncauses an exception, it will still cause issues.\n\nMaking operator= exception-safe also typically also renders it\nself-assignment-safe. It is common to deal with self-assignment issues by\nignoring them and isntead focusing on exception safety. A careful ordering\nof statements can make code exception safe. For example:\n\n```cpp\nWidget\u0026 Widget::operator=(const Widget\u0026 rhs)\n{\n    Bitmap *pOrig = pb;\n    pb = new Bitmap(*rhs.pb);\n    delete pOrig;\n\n    return *this;\n}\n```\n\n\u003e [!tip] Performance Hint  \n\u003e The identity test can still be placed at the top for efficiency, however,\n\u003e consider how often self-assignment occurs. The check is not free. It\n\u003e makes the source code and object bigger and introduces a branch.\n\u003e\n\nAlternative to manual ordering is the \"copy and swap\" technique.\n```cpp\nclass Widget {\n    ...\n    void swap(Widget\u0026 rhs); // exchanges *this and rhs's data\n    ...\n};\n\nWidget\u0026 Widget::operator=(const Widget\u0026 rhs)\n{\n    Widget temp(rhs);\n    swap(temp);\n    return *this;\n}\n```\n\nThe final variation sacrifices some clarity for allowing the compiler to\nsometimes generate more efficient code.\n```cpp\nWidget\u0026 Widget::operator=(Widget rhs) // rhs is a copy of the object\n{\n    swap(rhs);\n\n    return *this;\n}\n```\n\n\u003e [!abstract] Summary\n\u003e - Make sure operator= can handle self-assignment in a well-behaved\n\u003e manner\n\u003e - Make sure any function operating on more than one object behaves\n\u003e well if two or more of the objects are the same.\n\n### **Item 12:** Copy all parts of an object.\nWell-designed objects contain only two functions that copy objects: the\ncopy constructor and copy assignment operator. Compilers will generate\nthese functions if required and do what you expect them to: copy all the\ndata of the object being copied.\n\nHowever, when you declare your own copy functions, they do not warn you\nwhen your implementation is wrong. You may forget to copy a newly\nadded data member and there will be no warnings.\n\nAnother way that you may run into issues is when using inheritance.\n```cpp\nclass PriorityCustomer:public Customer {\npublic:\n    ...\n    PriorityCustomer(const PriorityCustomer\u0026 rhs);\n    PriorityCustomer\u0026 operator=(const PriorityCustomer\u0026 rhs);\n    ...\nprivate:\n    int priority;\n};\n\nPriorityCustomer::PriorityCustomer(const PriorityCustomer\u0026 rhs)\n: priority(rhs.priority)\n{\n    logCall(\"PriorityCustomer copy constructor\");\n}\n\nPriorityCustomer\u0026\nPriorityCustomer::operator=(const PriorityCustomer\u0026 rhs)\n{\n    logCall(\"PriorityCustomer copy assignment operator\");\n    priority = rhs.priority;\n    return *this;\n}\n```\n\nThis may look fine and appear to be copying everything, however, \ncrucially, they are not copying the data members it inherits from customer.\nThe fix to this would be the following:\n```cpp\n\nPriorityCustomer::PriorityCustomer(const PriorityCustomer\u0026 rhs)\n: Customer(rhs)                 // invoke base class copy ctor\n  priority(rhs.priority)\n{\n    logCall(\"PriorityCustomer copy constructor\");\n}\n\nPriorityCustomer\u0026\nPriorityCustomer::operator=(const PriorityCustomer\u0026 rhs)\n{\n    logCall(\"PriorityCustomer copy assignment operator\");\n    Customer::operator=(rhs);  // assign base class parts\n    priority = rhs.priority;\n    return *this;\n}\n```\n\n\u003e [!warning] Warning\n\u003e The two copy functions will have similar code but do not call one from\n\u003e the other as it is a non-sensical operation. If you really must, have the\n\u003e two call a third private function such as init().\n\n\u003e [!summary] Summary\n\u003e - Make sure copy functions copy all of an object's data members\n\u003e including the base class parts.\n\u003e - Don't implement one copy function in terms of the other. Put common\n\u003e code in a third function.\n\n## Ch3: Resource management  \n\n## Ch4: Designs and declarations  \n\n## Ch5: Implementations  \n\n## Ch6: Inheritance and Object-Oriented Design  \n\n## Ch7: Templates and generic programming  \n\n## Ch8: Customising `new` and `delete`  \n\n## Ch9: Miscellany  \n\n\n","lastmodified":"2023-03-01T02:53:36.126250768Z","tags":null},"/Sources/How-to-focus":{"title":"Dr. K - How do I focus?","content":"Author: [Dr K](Authors/Dr%20K.md)  \nLink: https://www.youtube.com/watch?v=BZPRX9X5V5I  \nTopics:  [Productivity](Topics/Productivity.md)  \n\n---\n\n## Problem Statement  \nThere is variabillity on human performance where somedays things\n'click' and you perform very well and on other days you perform poorly.\nThis is somewhat counterintuitive as tecnically you have more\nexperience and knowledge every time you attempt something, however,\nperformance still seems to vary.\n\n## The mind and the self\nThe self may say \"I need to focus\", however the mind \"does not want\nto focus\". First we must acknowledge there are different parts of\n'you'. The ability for the self to win involves the frontal lobe which\nis responsible for things such as ==impulse control, delayed gratification and directing attention==.\n\nThe question is how do we skew the balance in the favour of the self.\n\nIn order of what the mind wants to do:  \n1. High dopamine activity\n2. 'Productive' task\n3. The real work\n4. Boredom\n\nThe 'mind' wants to get to the high dopamine activity. It will distract you\nto force you into a state of boredom.\nYou can't tolerate boredom, so you'll tend towards something that is\nproductive but not the work you want to do.\nThen at that point you will tell yourself its ok to indulge in the high\ndopamine activity.\n\nCrucially the mind knows you hate boredom and will weaponise it against you\nto get to high dopamine activities. ALL of the minds power over you\nrevolves around boredom. However, ==you can tolerate boredom more than your mind can==.\n\nDue to the fact that you can tolerate boredom more than your 'mind',\nif you tell yourself that you only have two options: work or sleep;\nyour mind will eventually get productive due to the boredom.\n\n## Sitting with the self\nYou have to notice the various tricks you or your mind play on yourself.\nSometimes it may say that you need to do additional prep before you can\ndo a specific task.This may be true sometimes, or sometimes it can be\nthe mind just give you excuses not to do the task. You need to just\naccept that you will never truly be 'ready'.\n\nYou may also have the thought that since you can't focus today, you as\nwell enjoy the day. Yet again the conclusion is that you don't have to do\nthe work today.\n","lastmodified":"2023-03-01T02:53:36.126250768Z","tags":null},"/Sources/Leon-Hendrix-Journaled-for-1000-days.-What-I-learned.":{"title":"Leon Hendrix - Journaled for 1000 days. What I learned.","content":"\nAuthor: [Leon Hendrix](Authors/Leon%20Hendrix.md)  \nLink: https://www.youtube.com/watch?v=0UhZDFK2Pwc  \nTopics: [Journaling](Topics/Journaling.md)  \n\n---\n\n### 7 key points\n- Vison journaling  (visualisation) - motivation\n    - Inspired by Arnold Schwarzenegger - \"When your vision is powerful enough, everything else falls into place\"\n    - **Write down what your ideal life would look like**\n- 'Positive worry' - motivation\n    - What if ...(series of good things)... happens to me?\n    - **Write down a series of good things that could happen to you.**\n- Focus on the one most important thing - productivity\n    - Gary Keller - The One thing\n    - Steve Jobs - \"People think focus means saying yes to the thing you've got to focus on. But that's not what it means at all. It means saying no to the hundred other good ideas that there are.\"\n    - Steps:\n        - **Make a list of everything you COULD do**\n        - **Narrow your focus. \"What is the one thing I could do that would make everything else easier or even unnecessary?\"**\n- Think bigger. 10x exercise - productivity\n- The brain dump - counter anxiety\n    - **Write down all thoughts. No filters. Until everything you're worried about is written down.**\n    - **Reassess**\n- To counter procastrination - productivity\n    - Usually because you need more clarity. Three most common reasons are:\n        - Unclear effort\n        - Unsure about capability/competence\n        - Unclear on outcome\n    - Steps:\n        - **Ask why are you procrastinating**\n        - **Write down resisting thoughts.**\n        - **Dig deeper. Ask follow up questions**\n- Gratitude on steroids - Mood elevation\n","lastmodified":"2023-03-01T02:53:36.126250768Z","tags":null},"/Sources/Mental-Models-The-Best-Way-to-Make-Intelligent-Decisions~100-Models-Explained":{"title":"Mental Models - The Best Way to Make Intelligent Decisions(~100 Models Explained)","content":"\nAuthor: [Rhiannon Beaubien](Authors/Rhiannon%20Beaubien.md)  \nLink: [fs blog](https://fs.blog/mental-models/)  \nTopics: [Mental Models](Topics/Mental%20Models.md)  \n\n---\n\n## What are they?\n- **Representation** of how something works.\n- **Simplify** the complex with models into **understandable and organisable** chunks.\n\n- Shapes how we think and how we understand.\n- Shapes **connections and opportunities** we see.\n\n## Learning to think better\n- More models -\u003e bigger toolbox -\u003e more likely to have right models to grasp reality.\n- Decision making ability improves with variety of models.\n\n- Engineer thinks in systems, pyschologist in incentives, biologist in evolution etc.\n- Combining disciplines -\u003e analyse problem in 3D way.\n- Practical wisdom is not just isolated facts. They need to hang together on latticework of theory.\n\n### Core Mental Models\n- **The Map is Not the Territory**\n- **Circle of Competence**\n\t- Know what you understand. Know where your edge is over others.\n\t- Understanding circle of competence improves decision-making and outcomes.\n- First Principles Thinking\n- Thought Experiment\n- **Second-Order Thinking**\n\t- Thinking farther ahead than immeidate results.\n\t- Thinking holistically.\n- Probabilistic Thinking\n- Inversion\n- Occam's Razor\n- Hanlon's Razor","lastmodified":"2023-03-01T02:53:36.126250768Z","tags":null},"/Sources/Roam-Research-White-Paper":{"title":"Roam Research White Paper","content":"citation:  [White Paper](https://roamresearch.com/#/app/help/page/dZ72V0Ig6)  \nTopics:  [Productivity](Topics/Productivity.md)  \n\n---\nWe are experiencing an unprecedented explosion of knowledge, yet neither the human brain nor current technologies are equipped to ==harnesess== it to its ==full potential==.\n\n## Brief\n- Current approaches to knowledge management are ill suited for information age. They are usually 'cabinet like'.\n\t- Note: Presumable being hierarchical and isolated from one another.\n- Cabinet approach makes it difficult to share ideas across your files and lack interconnectivity.\n- Knowledge graphs are a more flexible data structure to tackle this challenge of knowledge management.\n- Basic users: ease of storage, recollection of ideas and cross-referencing of ideas\n- Power users: applications in logic and reasoning.\n- ==Optimising for serendipity==. Humans have difficulty generating random numbers, thoughts etc. Exposure to random 'noise' can be the stimuli to new insights. These new insights usually occur at the juncture of two seemingly unrelated concepts.\n- Roam's interconnectivity constantly creates opportunities for serendipity and new insights.\n- _Collaborative problem solving - separating the noise from the signal:_ Current learning/research protocols are bound by necessary consensus. As information increases, so does noise, making it difficult to come to a consensus. A curated knowledge graph allows weighing up of conflicting opinions and ideas to develop your own understanding without autocracy (listening to one trusted source) or democracy (waiting for a full consensus that might never come).\n","lastmodified":"2023-03-01T02:53:36.126250768Z","tags":null},"/Topics/AI":{"title":"AI","content":"","lastmodified":"2023-03-01T02:53:36.126250768Z","tags":null},"/Topics/Journaling":{"title":"Journaling","content":"","lastmodified":"2023-03-01T02:53:36.126250768Z","tags":null},"/Topics/Mental-Models":{"title":"Mental Models","content":"","lastmodified":"2023-03-01T02:53:36.126250768Z","tags":null},"/Topics/Productivity":{"title":"Productivity","content":"","lastmodified":"2023-03-01T02:53:36.126250768Z","tags":null},"/Topics/Software-Engineering":{"title":"Software Engineering","content":"","lastmodified":"2023-03-01T02:53:36.126250768Z","tags":null},"/Work-with-the-garage-door-up":{"title":"Work with the garage door up","content":"References:  [Work with the garage door up - Andy Matuschak](https://notes.andymatuschak.org/About_these_notes?stackedNotes=z21cgR9K3UcQ5a7yPsj2RUim3oM2TzdBByZu\u0026stackedNotes=z2DABWsGLkXcCuUet2scfD1duL1ZHBztwGKp) [Learn in public](https://www.swyx.io/learn-in-public)  \nTopics:  [Productivity](Topics/Productivity.md)  \n\n---\n\n\"Work with the garage door up\" is the idea that you should share what you're working on and learning to the public. The idea is that by sharing your work, you can document your progress and allow people to provide feedback, inspiration and support.  \n\nWorking with the garage door up can also have a motivating aspect to it. If you are publishing your development, you are more likely to keep consistent as well as to think through your ideas more. The transparency and openness also makes it naturally align with the philosophy of [anti-marketing](Anti-marketing.md).     \n\nIt seems to have similarities with the 'rubber duck debugging' method where even if no one is reading your notes/posts, the idea that it might be read by other people forces your mind to process the information more carefully which makes your own learning more effective.","lastmodified":"2023-03-01T02:53:36.126250768Z","tags":null}}